#!/usr/bin/env ruby

$LOAD_PATH.unshift(File.expand_path('../lib/circleci-tools', __dir__))

require 'thor'
require 'tty-prompt'
require 'json'
require 'csv'
require 'date'
require 'active_support/all'

require 'api_service'
require 'job_analyzer'
require 'runner_calculator'
require 'data_aggregator'
require 'log_uploader'
require 'usage_report_service'
require 'cloudwatch_metrics_service'
require 's3_upload_service'
require 'resource_usage_aggregator'

module CircleciMetrics
  class CLI < Thor
    desc "evaluate", "Evaluate concurrency requirements for self-hosted runners"

    method_option :org, aliases: '-o', type: :string, desc: 'VCS org'
    method_option :project, aliases: '-p', type: :string, desc: 'Project name'
    method_option :days, aliases: '-d', type: :numeric, desc: 'Number of days to look back for pipelines', default: 30
    method_option :pipelines_json, type: :string, desc: 'Path to JSON file with pre-fetched pipelines'
    method_option :jobs_json, aliases: '-jjson', type: :string, desc: 'Path to JSON file with pre-fetched jobs'

    def evaluate
      prompt = TTY::Prompt.new

      org = fetch_param(:org, 'CIRCLECI_ORG', prompt, "Enter your VCS org:")
      project = fetch_param(:project, 'CIRCLECI_PROJECT', prompt, "Enter your project name:")
      days = options[:days]

      api_token = fetch_api_token(prompt)

      circleci_service = CircleciTools::ApiService.new(api_token:, org:, project:)
      job_analyzer = CircleciTools::JobAnalyzer.new
      runner_calculator = CircleciTools::RunnerCalculator.new

      pipelines = load_or_fetch_pipelines(circleci_service, org, project, days)
      puts "Fetched pipelines: #{pipelines.size}"

      return if pipelines.empty?

      all_jobs = load_or_fetch_jobs(circleci_service, pipelines)
      return if all_jobs.empty?

      puts "Calculating peak RAM usage..."
      peak_ram = job_analyzer.calculate_peak_ram(jobs: all_jobs)
      puts "Peak concurrent RAM required: #{peak_ram} MB"

      recommended_runners = runner_calculator.calculate_runners(peak_ram)
      puts "Recommended number of runners (#{runner_calculator.runner_ram_gb} GB each): #{recommended_runners}"

      aggregator = CircleciTools::DataAggregator.new(all_jobs)

      aggregator.generate_csv
    end

    desc "upload", "Store aggregated CSV data into SQLite database for analysis"

    method_option :csv_file_path, aliases: '-c', type: :string, required: true, desc: 'Path to the aggregated CSV file'
    method_option :log_group_name, aliases: '-l', type: :string, default: '/CircleCi', desc: 'Log group name'
    method_option :dry_run, type: :boolean, default: false, desc: 'Dry run mode'

    def upload
      csv_file_path = options[:csv_file_path]
      log_group_name = options[:log_group_name]

      importer = CircleciTools::LogUploader.new(log_group_name, dry_run: options[:dry_run])
      importer.upload_file(csv_file_path)
    end

    desc "aggregate", "Aggregate data from an existing jobs JSON file"

    method_option :jobs_json, aliases: '-j', type: :string, desc: 'Path to JSON file with jobs'

    def aggregate
      jobs_json_path = options[:jobs_json] || abort("Error: --jobs_json option is required")
      jobs = JSON.parse(File.read(jobs_json_path))
      aggregator = CircleciTools::DataAggregator.new(jobs)
      aggregator.generate_csv
    end

    desc "usage_report", "Create usage export job, download CSV, and print file references"
    method_option :org_id, type: :string, desc: 'Organization ID'
    method_option :shared_org_ids, type: :array, desc: 'Shared organization IDs'
    method_option :dry_run, type: :boolean, default: false, desc: 'Dry run mode'
    method_option :verbose, aliases: '-v', type: :boolean, default: false, desc: 'Enable verbose logging'
    method_option :days_ago, type: :numeric, default: 0, desc: 'Number of days to look back from now'
    method_option :months_ago, type: :numeric, default: nil, desc: 'Number of months to look back from now'
    method_option :usage_export_job_id, aliases: 'j', type: :string, desc: 'Existing usage export job ID'
    method_option :upload, type: :boolean, default: false, desc: 'Upload the usage report to CloudWatch'
    method_option :s3_bucket, type: :string, desc: 'S3 bucket name for uploading the usage report'
    def usage_report
      prompt = TTY::Prompt.new
      org_id = options[:org_id] || ENV.fetch('CIRCLE_ORGANIZATION_ID')

      shared_org_ids = options[:shared_org_ids] || []
      api_token = fetch_api_token(prompt) # ...call existing helper or use logic shown in evaluate method
      log_level = options[:verbose] ? Logger::DEBUG : Logger::INFO
      logger = Logger.new(STDOUT)
      logger.level = log_level

      circleci_service = CircleciTools::ApiService.new(api_token:, org: 'N/A', project: 'N/A', logger:)
      usage_report_service = CircleciTools::UsageReportService.new(
        circleci_service,
        org_id,
        shared_org_ids,
        600,
        logger: logger,
        log_level: log_level
      )

      usage_export_job_id = options[:usage_export_job_id]
      if usage_export_job_id
        downloaded_files = usage_report_service.call(usage_export_job_id:)
      else
        current_time = Time.now.utc
        if options[:months_ago]
          months_ago = options[:months_ago]
          if months_ago.zero?
            start_time = current_time.beginning_of_month
            end_time = current_time
          else
            start_time = (current_time - months_ago.months).beginning_of_month
            end_time = (current_time - months_ago.months).end_of_month
          end
        elsif options[:days_ago]
          days_ago = options[:days_ago]
          if days_ago.zero?
            start_time = current_time.beginning_of_day
            end_time = current_time
          else
            start_time = (current_time - days_ago.days).beginning_of_day
            end_time = (current_time - days_ago.days).end_of_day
          end
        else
          raise "Either days_ago or months_ago must be specified"
        end

        begin
          downloaded_files = usage_report_service.call(start_time:, end_time:)
        rescue RuntimeError => e
          puts "Error: #{e.message}"
          exit(1)
        end
      end

      csv_files = downloaded_files.select { |file| file.end_with?('.csv') }

      if csv_files.size == 0
        puts "No usage report available for the given time range."
      elsif csv_files.size == 1
        puts "Usage report file downloaded: #{csv_files.first}"
      else
        puts "Usage report files downloaded:"
        csv_files.each { |f| puts "  - #{f}" }
      end

      if options[:s3_bucket]
        s3_service = CircleciTools::S3UploadService.new(options[:s3_bucket], logger: logger)
        csv_files.each do |file|
          s3_key = File.basename(file)
          s3_service.upload_file(file, s3_key)
        end
      end

      if options[:upload]
        if !options[:s3_bucket]
          unless prompt.yes?("Warning: No S3 bucket specified. Events could be uploaded multiple times. Do you want to continue?")
            puts "Operation aborted."
            exit(1)
          end
        end

        metrics_service = CircleciTools::CloudWatchMetricsService.new(
          namespace: 'CircleCI',
          dry_run: options[:dry_run],
          s3_bucket: options[:s3_bucket]
        )
        csv_files.each do |file|
          metrics_service.upload_metrics(file)
        end
      end
    end

    desc "upload_metrics", "Upload CloudWatch metrics from CSV file"
    method_option :csv_file_path, aliases: '-c', type: :string, required: true, desc: 'Path to the CSV file'
    method_option :namespace, aliases: '-n', type: :string, default: 'CircleCI', desc: 'CloudWatch namespace'
    method_option :dry_run, type: :boolean, default: false, desc: 'Dry run mode'
    def upload_metrics
      csv_file_path = options[:csv_file_path]
      namespace = options[:namespace]
      dry_run = options[:dry_run]

      metrics_service = CircleciTools::CloudWatchMetricsService.new(namespace: namespace, dry_run: dry_run)
      metrics_service.upload_metrics(csv_file_path)
    end

    desc "aggregate_usage", "Aggregate resource usage for jobs"
    method_option :job_ids, aliases: '-j', type: :array, desc: 'List of Job IDs', required: true
    method_option :verbose, aliases: '-v', type: :boolean, default: false, desc: 'Enable verbose output'
    method_option :format, aliases: '-f', type: :string, enum: ['text', 'json'], default: 'text', desc: 'Output format (text or json)'
    def aggregate_usage
      job_ids = options[:job_ids]
      api_token = fetch_api_token(TTY::Prompt.new)
      logger = Logger.new(STDOUT)
      logger.level = options[:verbose] ? Logger::DEBUG : Logger::INFO

      circleci_service = CircleciTools::ApiService.new(api_token:, org: 'N/A', project: 'N/A', logger:)
      aggregator = CircleciTools::ResourceUsageAggregator.new(logger:)

      puts "Fetching usage data for #{job_ids.size} job#{'s' if job_ids.size > 1}..." unless options[:format] == 'json'
      usage_data = []
      failed_jobs = []

      job_ids.each do |job_id|
        begin
          data = circleci_service.fetch_resource_usage(job_id)
          usage_data << data
          puts "Successfully fetched data for job #{job_id}" if options[:verbose]
        rescue => e
          failed_jobs << job_id
          puts "Failed to fetch data for job #{job_id}: #{e.message}" if options[:verbose]
        end
      end

      if usage_data.empty?
        if options[:format] == 'json'
          puts JSON.pretty_generate({ error: "No usage data could be fetched" })
        else
          puts "No usage data could be fetched."
        end
        return
      end

      if options[:verbose]
        puts "\nFetched usage data:"
        puts JSON.pretty_generate(usage_data)
      end

      result = aggregator.aggregate(usage_data)
      
      case options[:format]
      when 'json'
        json_output = {
          jobs: {
            total: job_ids.size,
            processed: job_ids.size - failed_jobs.size,
            failed: failed_jobs
          },
          tasks: result[:stats][:tasks_processed],
          samples: result[:stats][:samples_processed],
          metrics: {
            cpu: {
              min: result[:metrics][:cpu][:min].round(3),
              max: result[:metrics][:cpu][:max].round(3),
              avg: result[:metrics][:cpu][:avg].round(3)
            },
            memory: {
              min: (result[:metrics][:memory_bytes][:min] / 1024.0 / 1024.0).round(2),
              max: (result[:metrics][:memory_bytes][:max] / 1024.0 / 1024.0).round(2),
              avg: (result[:metrics][:memory_bytes][:avg] / 1024.0 / 1024.0).round(2),
              unit: 'MB'
            }
          }
        }
        puts JSON.pretty_generate(json_output)
      else
        puts aggregator.format_summary(result, jobs_total: job_ids.size, failed_jobs:)
        if options[:verbose] && result
          puts "\nRaw metrics:"
          puts JSON.pretty_generate(result[:metrics])
        end
      end
    end

    no_commands do
      def load_or_fetch_pipelines(circleci_service, org, project, days)
        if options[:pipelines_json]
          puts "Loading pipelines from JSON file: #{options[:pipelines_json]}"
          JSON.parse(File.read(options[:pipelines_json]))
        else
          puts "Fetching pipelines for project #{org}/#{project} that ran in the last #{days} days..."
          pipelines = circleci_service.fetch_pipelines(days: days)
          puts "Total pipelines fetched: #{pipelines.size}"

          timestamp = Time.now.strftime('%Y%m%d%H%M%S')
          filename = "tmp/pipelines_#{org}_#{project}_#{timestamp}.json"
          File.write(filename, JSON.pretty_generate(pipelines))
          puts "Pipelines exported to #{filename}"

          pipelines
        end
      end

      def load_or_fetch_jobs(circleci_service, pipelines)
        if options[:jobs_json]
          puts "Loading jobs from JSON file: #{options[:jobs_json]}"
          JSON.parse(File.read(options[:jobs_json]))
        else
          puts "Fetching jobs for all pipelines..."
          all_jobs = circleci_service.fetch_all_jobs(pipelines)
          puts "Total jobs fetched: #{all_jobs.size}"

          timestamp = Time.now.strftime('%Y%m%d%H%M%S')
          filename = "tmp/jobs_#{timestamp}.json"
          File.write(filename, JSON.pretty_generate(all_jobs))
          puts "Jobs exported to #{filename}"

          all_jobs
        end
      end

      def fetch_param(option_key, env_var, prompt, message)
        if options[option_key]
          options[option_key]
        else
          ENV.fetch(env_var) do
            if $stdin.tty?
              prompt.ask(message) { |q| q.required(true) }
            else
              abort("Error: Environment variable #{env_var} is not set and no option provided.")
            end
          end
        end
      rescue KeyError
        if $stdin.tty?
          prompt.ask(message) { |q| q.required(true) }
        else
          abort("Error: Environment variable #{env_var} is not set and no option provided.")
        end
      end

      def fetch_api_token(prompt)
        ENV.fetch('CIRCLECI_API_TOKEN') do
          if $stdin.tty?
            prompt.mask("Enter your CircleCI API Token:") { |q| q.required(true) }
          else
            abort("Error: Environment variable CIRCLECI_API_TOKEN is not set and no option provided.")
          end
        end
      rescue KeyError
        if $stdin.tty?
          prompt.mask("Enter your CircleCI API Token:") { |q| q.required(true) }
        else
          abort("Error: Environment variable CIRCLECI_API_TOKEN is not set and no option provided.")
        end
      end
    end
  end
end

CircleciMetrics::CLI.start(ARGV)
